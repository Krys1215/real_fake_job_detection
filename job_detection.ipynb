{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Marketing Intern Marketing We're Food52, and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Customer Service - Cloud Video Production Succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)   Valo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Account Executive - Washington DC Sales Our pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Bill Review Manager   SpotSource Solutions LLC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraudulent                                               text\n",
       "0           0  Marketing Intern Marketing We're Food52, and w...\n",
       "1           0  Customer Service - Cloud Video Production Succ...\n",
       "2           0  Commissioning Machinery Assistant (CMA)   Valo...\n",
       "3           0  Account Executive - Washington DC Sales Our pa...\n",
       "4           0  Bill Review Manager   SpotSource Solutions LLC..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_path = os.getcwd()\n",
    "file_path = curr_path + '/dataset/fake_job_postings.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.fillna(' ',inplace=True)\n",
    "df['text']=df['title']+\" \" + df['department'] + \" \" + df['company_profile'] + \" \" + df['description'] + \" \" + df['requirements'] + \" \" + df['benefits'] + \" \" \n",
    "delete_list=['job_id','title','location','telecommuting','has_company_logo','has_questions','department','salary_range','company_profile','description','requirements','benefits','employment_type','required_experience','required_education','industry','function']\n",
    "df = df.drop(delete_list, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只把第一行拿出来试试，要不太慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Marketing Intern Marketing We're Food52, and we've created a groundbreaking and award-winning cooking site. We support, connect, and celebrate home cooks, and give them everything they need in one place.We have a top editorial, business, and engineering team. We're focused on using technology to find new and better ways to connect people around their specific food interests, and to offer them superb, highly curated information about food and cooking. We attract the most talented home cooks and contributors in the country; we also publish well-known professionals like Mario Batali, Gwyneth Paltrow, and Danny Meyer. And we have partnerships with Whole Foods Market and Random House.Food52 has been named the best food website by the James Beard Foundation and IACP, and has been featured in the New York Times, NPR, Pando Daily, TechCrunch, and on the Today Show.We're located in Chelsea, in New York City. Food52, a fast-growing, James Beard Award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its New York City headquarters.Reproducing and/or repackaging existing Food52 content for a number of partner sites, such as Huffington Post, Yahoo, Buzzfeed, and more in their various content management systemsResearching blogs and websites for the Provisions by Food52 Affiliate ProgramAssisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiriesSupporting with PR &amp; Events when neededHelping with office administrative work, such as filing, mailing, and preparing for meetingsWorking with developers to document bugs and suggest improvements to the siteSupporting the marketing and executive staff Experience with content management systems a major plus (any blogging counts!)Familiar with the Food52 editorial voice and aestheticLoves food, appreciates the importance of home cooking and cooking with the seasonsMeticulous editor, perfectionist, obsessive attention to detail, maddened by typos and broken links, delighted by finding and fixing themCheerful under pressureExcellent communication skillsA+ multi-tasker and juggler of responsibilities big and smallInterested in and engaged with social media like Twitter, Facebook, and PinterestLoves problem-solving and collaborating to drive Food52 forwardThinks big picture but pitches in on the nitty gritty of running a small company (dishes, shopping, administrative support)Comfortable with the realities of working for a startup: being on call on evenings and weekends, and working long hours   \"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = df.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11311\\AppData\\Local\\Temp\\ipykernel_5984\\4242022306.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text']=df['text'].str.replace('\\n','')\n",
      "C:\\Users\\11311\\AppData\\Local\\Temp\\ipykernel_5984\\4242022306.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text']=df['text'].str.replace('\\r','')\n",
      "C:\\Users\\11311\\AppData\\Local\\Temp\\ipykernel_5984\\4242022306.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text']=df['text'].str.replace('\\t','')\n",
      "C:\\Users\\11311\\AppData\\Local\\Temp\\ipykernel_5984\\4242022306.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: re.sub(r'[0-9]','',x))\n",
      "C:\\Users\\11311\\AppData\\Local\\Temp\\ipykernel_5984\\4242022306.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: re.sub(r'[/(){}\\[\\]\\|@,;.:-]',' ',x))\n",
      "C:\\Users\\11311\\AppData\\Local\\Temp\\ipykernel_5984\\4242022306.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text']= df['text'].apply(lambda s:s.lower() if type(s) == str else s)\n",
      "C:\\Users\\11311\\AppData\\Local\\Temp\\ipykernel_5984\\4242022306.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text']=df['text'].str.replace('  ',' ')\n",
      "C:\\Users\\11311\\AppData\\Local\\Temp\\ipykernel_5984\\4242022306.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] =df['text'].apply(lambda x: ' '.join([word for word in x.split() if nlp.vocab[word].is_stop==False ]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>marketing intern marketing we're food we've cr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraudulent                                               text\n",
       "0           0  marketing intern marketing we're food we've cr..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleanups\n",
    "def data_cleanups(df:pd.DataFrame):\n",
    "    df['text']=df['text'].str.replace('\\n','')\n",
    "    df['text']=df['text'].str.replace('\\r','')\n",
    "    df['text']=df['text'].str.replace('\\t','')\n",
    "  \n",
    "  #This removes unwanted texts\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'[0-9]','',x))\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'[/(){}\\[\\]\\|@,;.:-]',' ',x))\n",
    "  \n",
    "  #Converting all upper case to lower case\n",
    "    df['text']= df['text'].apply(lambda s:s.lower() if type(s) == str else s)\n",
    "  \n",
    "  #Remove un necessary white space\n",
    "    df['text']=df['text'].str.replace('  ',' ')\n",
    "\n",
    "  #Remove Stop words\n",
    "    nlp=spacy.load(\"en_core_web_sm\") # python -m spacy download en_core_web_sm \n",
    "    df['text'] =df['text'].apply(lambda x: ' '.join([word for word in x.split() if nlp.vocab[word].is_stop==False ]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "first_row = data_cleanups(first_row)\n",
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11311\\AppData\\Local\\Temp\\ipykernel_5984\\1179493015.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_row['processed']=pd.Series(output)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>marketing intern marketing we're food we've cr...</td>\n",
       "      <td>market intern marketing we be food we have cre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fraudulent                                               text  \\\n",
       "0           0  marketing intern marketing we're food we've cr...   \n",
       "\n",
       "                                           processed  \n",
       "0  market intern marketing we be food we have cre...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spacy.load('en_core_web_sm')\n",
    "output=[]\n",
    "\n",
    "for sentence in first_row['text']:\n",
    "    sentence=sp(str(sentence))\n",
    "    s=[token.lemma_ for token in sentence]\n",
    "    output.append(' '.join(s))\n",
    "first_row['processed']=pd.Series(output)\n",
    "\n",
    "first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用新的tokenizer是返回的NP array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100000\n",
    "embedding_dim = 64\n",
    "max_length = 250\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 20000\n",
    "#Tokenization\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(first_row['processed'].values)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X = tokenizer.texts_to_sequences(first_row['processed'].values)    # Tokenize the dataset\n",
    "X = pad_sequences(X, maxlen=max_length)   # Padding the dataset\n",
    "Y = first_row['fraudulent']       #Assign the value of y  \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,  13,  14,  15,   2,   6,   1,   2,  35,  36,  37,  16,\n",
       "         17,   7,  38,   8,  18,  39,   9,   7,  40,  41,  19,  42,  43,\n",
       "         20,   2,   6,  44,  45,  46,   3,  47,  48,  18,  49,  50,   1,\n",
       "         51,  52,  53,  54,  21,  55,   1,  10,  56,  57,   9,   7,  58,\n",
       "         59,  60,  61,  62,  22,  63,  64,  65,  66,  67,  68,  69,   1,\n",
       "         13,  70,  71,   1,  72,  73,   1,  23,  24,  25,  74,  75,  76,\n",
       "          3,  11,  77,  78,  79,  80,  81,  82,   2,   6,  83,  84,   3,\n",
       "         11,  26,   1,  85,  86,  24,  25,  16,  17,  87,   1,  88,  89,\n",
       "         90,  21,  91,  92,  93,  94,  95,  96,  14,   4,  27,  20,  28,\n",
       "         29,  30,   3,  11,  26,  97,  98,  99, 100,   1,  12, 101, 102,\n",
       "        103, 104, 105, 106, 107,  12,  31, 108, 109,  23, 110,   1,   5,\n",
       "        111,  32,  32,   5, 112,   8, 113,   5, 114,   5, 115, 116, 117,\n",
       "        118, 119, 120,  33,   4, 121, 122, 123, 124,  30, 125, 126, 127,\n",
       "        128, 129,  15,  29, 130, 131,  12,  31, 132, 133, 134, 135, 136,\n",
       "        137,   1,  19, 138, 139,   1, 140, 141,   9,  10,  10, 142,  28,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161,  34, 162, 163, 164, 165,  22, 166,\n",
       "        167, 168, 169, 170, 171, 172,   1, 173,  34, 174, 175, 176, 177,\n",
       "        178,  27, 179, 180, 181,  33,   8, 182, 183,   4, 184, 185, 186,\n",
       "          4, 187, 188]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来试试用老的tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def read_tokenizer_wordIndex():\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        loaded_tokenizer = pickle.load(handle)\n",
    "    # 加载 word_index\n",
    "    with open('word_index.pickle', 'rb') as handle:\n",
    "        loaded_word_index = pickle.load(handle)\n",
    "        \n",
    "    return loaded_tokenizer, loaded_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,  13,  14,  15,   2,   6,   1,   2,  35,  36,  37,  16,\n",
       "         17,   7,  38,   8,  18,  39,   9,   7,  40,  41,  19,  42,  43,\n",
       "         20,   2,   6,  44,  45,  46,   3,  47,  48,  18,  49,  50,   1,\n",
       "         51,  52,  53,  54,  21,  55,   1,  10,  56,  57,   9,   7,  58,\n",
       "         59,  60,  61,  62,  22,  63,  64,  65,  66,  67,  68,  69,   1,\n",
       "         13,  70,  71,   1,  72,  73,   1,  23,  24,  25,  74,  75,  76,\n",
       "          3,  11,  77,  78,  79,  80,  81,  82,   2,   6,  83,  84,   3,\n",
       "         11,  26,   1,  85,  86,  24,  25,  16,  17,  87,   1,  88,  89,\n",
       "         90,  21,  91,  92,  93,  94,  95,  96,  14,   4,  27,  20,  28,\n",
       "         29,  30,   3,  11,  26,  97,  98,  99, 100,   1,  12, 101, 102,\n",
       "        103, 104, 105, 106, 107,  12,  31, 108, 109,  23, 110,   1,   5,\n",
       "        111,  32,  32,   5, 112,   8, 113,   5, 114,   5, 115, 116, 117,\n",
       "        118, 119, 120,  33,   4, 121, 122, 123, 124,  30, 125, 126, 127,\n",
       "        128, 129,  15,  29, 130, 131,  12,  31, 132, 133, 134, 135, 136,\n",
       "        137,   1,  19, 138, 139,   1, 140, 141,   9,  10,  10, 142,  28,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161,  34, 162, 163, 164, 165,  22, 166,\n",
       "        167, 168, 169, 170, 171, 172,   1, 173,  34, 174, 175, 176, 177,\n",
       "        178,  27, 179, 180, 181,  33,   8, 182, 183,   4, 184, 185, 186,\n",
       "          4, 187, 188]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_tokenizer, loaded_word_index = read_tokenizer_wordIndex()\n",
    "\n",
    "X_new = tokenizer.texts_to_sequences(first_row['processed'].values)    # Tokenize the dataset\n",
    "X_new = pad_sequences(X_new, maxlen=max_length)   # Padding the dataset\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X is X_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
